{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deaedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic utils\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from rich.traceback import install\n",
    "install(show_locals=False, suppress=[\"torch\", \"timm\", \"pytorch_lightning\"])\n",
    "\n",
    "# image processing\n",
    "from PIL  import Image\n",
    "import cv2\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# timm\n",
    "import timm\n",
    "from timm.optim import create_optimizer_v2\n",
    "\n",
    "# pytorch lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "# logging\n",
    "from loguru import logger\n",
    "\n",
    "# albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.augmentations.geometric.transforms import Affine as AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'repvgg_a2'\n",
    "project_name = 'clock'\n",
    "\n",
    "configs = dict()\n",
    "configs['BATCH_SIZE'] = 64\n",
    "configs['LEARNING_RATE'] = 0.0001\n",
    "configs['EPOCHS'] = 20\n",
    "configs['TEST_SIZE'] = 0.25\n",
    "configs['SEED'] = 1203\n",
    "configs['WEIGHT_DECAY'] = 0.001\n",
    "configs['NUM_GPUS'] = torch.cuda.device_count()\n",
    "\n",
    "configs['SIZE'] = 224\n",
    "\n",
    "folder_name = f\"./checkpoints/{model_name}_{configs['SEED']}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef114e67",
   "metadata": {},
   "source": [
    "# 0. Set Strateges\n",
    "\n",
    "- Needs only two objects : Hour hand / minute hand -> remove noises\n",
    "\n",
    "\n",
    "- Preprocessing\n",
    "    - Background Removal -> X 연산량에 비해 효용이 떨어짐. \n",
    "    - Gray Scaling \n",
    "    - Center Crop -> 1.5배 resize -> 1 centercrop\n",
    "    \n",
    "\n",
    "- Possible objects : \n",
    "    - Classification\n",
    "        - hours   : 12 classes  \n",
    "        - minutes : 60 classes  \n",
    "            - single label classification : 12 * 60 classes  \n",
    "            - multi  label classification : 12 classes / 60 classes  \n",
    "    - Regression  \n",
    "        - hours : 0 ~ 12  \n",
    "        - minutes : 0 ~ 60\n",
    "    - Object detection + classification -> box label 필요 : 시간 안에 못할 것    \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "- Data Augmentation  \n",
    "    - rotation : add 1 minutes\n",
    "        - 6 degrees for minute hand \n",
    "        - 0.5 degree for hour hand\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92fc3c",
   "metadata": {},
   "source": [
    "## dirty data !\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "- classification을 혼란스럽게 만드는 image들이 존재함  \n",
    "- 어떻게 해야 할까... labeling을 하기에는 시간이 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e11abf",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing & Augmentation\n",
    "\n",
    "### original images\n",
    "    - 5-minute unit  \n",
    "    - 몇몇 image는 rotate 되어 있음 (90도) -> 시간 없으니 그냥 무시하고 진행\n",
    "    \n",
    "### preprocessing  \n",
    "    - 다수결 voting이 가능한 processing 방법이 있다면 도입하고 싶다.  \n",
    "        - normal images + rotated images -> rotated images 분리\n",
    "### augmented images \n",
    "    - +6, +12, +18, +24 / -6, -12, -18, -24  \n",
    "    - 1, 2, 3, 4 minute rotates\n",
    "    \n",
    "- 분침과 시침의 변화각도가 다르다. 어떻게 해결할까?  \n",
    "    - 같은 image를 이용하여 6도, 12도로 rotate 시킨 image를 두 개 만든다  \n",
    "    - 각각의 이미지에서 시침, 분침이 위치하는 지점만 반으로 쪼개서 갖고 온다.  \n",
    "    \n",
    "#### case 1. \n",
    "- 분침 : 20분~40분 사이  \n",
    "- 시침 : 9시 ~ 3시 사이 (10시, 11시, 12시, 1시, 2시)  \n",
    "\n",
    "#### case 2. \n",
    "- 분침 : 50분~10분 사이  \n",
    "- 시침 : 4시 ~ 8시 사이 (10시, 11시, 12시, 1시, 2시)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a30ef4",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de06c3",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b8b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = './data/train'\n",
    "train_data = []\n",
    "for name in os.listdir(train_folder):\n",
    "    cur_hour = name.split(\"-\")[0]\n",
    "    cur_min  = name.split(\"-\")[1]\n",
    "    cur_files = glob.glob(f\"{train_folder}/{name}/*.jpg\")\n",
    "    for file in cur_files:\n",
    "        train_data.append([file, cur_hour, cur_min])\n",
    "\n",
    "train = pd.DataFrame(train_data)\n",
    "train.columns = ['path', 'hour', 'min']\n",
    "train['path'] = train['path'].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881c550",
   "metadata": {},
   "source": [
    "## Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0990d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_folder = './data/test1'\n",
    "test1_data = []\n",
    "for name in os.listdir(test1_folder):\n",
    "    cur_hour = name.split(\"-\")[0]\n",
    "    cur_min  = name.split(\"-\")[1]\n",
    "    cur_files = glob.glob(f\"{test1_folder}/{name}/*.jpg\")\n",
    "    for file in cur_files:\n",
    "        test1_data.append([file, cur_hour, cur_min])\n",
    "\n",
    "test1 = pd.DataFrame(test1_data)\n",
    "test1.columns = ['path', 'hour', 'min']\n",
    "test1['path'] = test1['path'].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "test1[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedefe1",
   "metadata": {},
   "source": [
    "## Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_folder = './data/test2'\n",
    "test2_data = []\n",
    "for name in os.listdir(test2_folder):\n",
    "    cur_hour = name.split(\"-\")[0]\n",
    "    cur_min  = name.split(\"-\")[1]\n",
    "    cur_files = glob.glob(f\"{test2_folder}/{name}/*.jpg\")\n",
    "    for file in cur_files:\n",
    "        test2_data.append([file, cur_hour, cur_min])\n",
    "\n",
    "test2 = pd.DataFrame(test2_data)\n",
    "test2.columns = ['path', 'hour', 'min']\n",
    "test2['path'] = test2['path'].str.replace(\"\\\\\", \"/\", regex=False)\n",
    "test2[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76452dca",
   "metadata": {},
   "source": [
    "## Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5affe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, X, Y1, Y2, size, mode='train'):\n",
    "        self.X = X\n",
    "        self.Y1 = Y1\n",
    "        self.Y2 = Y2\n",
    "        self.size = size\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.transform(cv2.imread(train['path'][idx], cv2.IMREAD_GRAYSCALE))\n",
    "        \n",
    "        if self.mode in ['train', 'val']:\n",
    "            delta = random.randint(0, 4)\n",
    "            y1 = self.Y1[idx]\n",
    "            y2 = self.Y2[idx]\n",
    "            \n",
    "            x, delta = self.rotate(\n",
    "                img=x, delta=delta, hour=y1, minute=y2\n",
    "            )\n",
    "            y2 = y2+delta\n",
    "            \n",
    "            y1 = torch.tensor(y1).reshape(1, -1)\n",
    "            y2 = torch.tensor(y2).reshape(1, -1)\n",
    "            return ToTensorV2()(image=x)['image'].float(), y1, y2\n",
    "        else:\n",
    "            return ToTensorV2()(image=x)['image'].float()\n",
    "        \n",
    "    def transform(self, x):\n",
    "        tf = A.Compose([\n",
    "            A.Resize(height=self.size, width=self.size),\n",
    "        ])\n",
    "        return tf(image=x)['image']\n",
    "    \n",
    "\n",
    "    def rotate(self, img, delta:int, hour:int, minute:int): \n",
    "        # minute MUST be in [0, 1, 2, 3, 4]\n",
    "\n",
    "        if (hour in [9, 10, 11, 12, 1, 2]) and (15<=minute<=40):\n",
    "            case = 0\n",
    "        elif (hour in [3, 4, 5, 6, 7, 8]) and (45<=minute<=59 or 0<=minute<=10):\n",
    "            case = 1\n",
    "        else:\n",
    "            return img, 0\n",
    "\n",
    "        size = img.shape[0]\n",
    "\n",
    "        up_delta   = -0.5*delta if case == 0 else -6*delta\n",
    "        down_delta = -0.5*delta if case == 1 else -6*delta\n",
    "\n",
    "        # up\n",
    "        up_M   = cv2.getRotationMatrix2D( \n",
    "            (img.shape[0]/2.0 , img.shape[1]/2.0), \n",
    "            -0.5*delta, \n",
    "            1.1)\n",
    "        up = cv2.warpAffine(\n",
    "            img, \n",
    "            up_M, \n",
    "            (img.shape[1], img.shape[0]),\n",
    "            borderMode=cv2.BORDER_CONSTANT,\n",
    "           borderValue=(255,255)\n",
    "        )[:size//2]\n",
    "\n",
    "        # down\n",
    "        down_M   = cv2.getRotationMatrix2D( \n",
    "            (img.shape[0]/2.0 , img.shape[1]/2.0), \n",
    "            -6*delta, \n",
    "            1.1)\n",
    "        down = cv2.warpAffine(\n",
    "            img, \n",
    "            down_M, \n",
    "            (img.shape[1], img.shape[0]),\n",
    "            borderMode=cv2.BORDER_CONSTANT,\n",
    "           borderValue=(255,255)\n",
    "        )[size//2:]\n",
    "        augmented = cv2.vconcat([up, down])\n",
    "\n",
    "        return augmented, delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self, configs,\n",
    "        X, Y1, Y2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.configs=configs\n",
    "        self.X = X\n",
    "        self.Y1 = Y1.astype(int)\n",
    "        self.Y2 = Y2.astype(int)\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        if stage=='fit':\n",
    "            X_train, X_val, Y1_train, Y1_val, Y2_train, Y2_val = train_test_split(\n",
    "                self.X, self.Y1, self.Y2,\n",
    "                test_size=self.configs['TEST_SIZE'],\n",
    "                random_state=self.configs['SEED'],\n",
    "            )\n",
    "            \n",
    "            self.train_dataset = BaseDataset(\n",
    "                X_train, Y1_train, Y2_train, configs['SIZE'], mode='train'\n",
    "            )\n",
    "            self.val_dataset = BaseDataset(\n",
    "                X_val, Y1_val, Y2_val, configs['SIZE'], mode='val'\n",
    "            )\n",
    "            \n",
    "        if stage=='predict':\n",
    "            self.test_dataset = BlockDataset(\n",
    "                self.X, self.Y1, self.Y2, configs['SIZE'], mode='predict')\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.configs['BATCH_SIZE'],\n",
    "            num_workers=4,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.configs['BATCH_SIZE'],\n",
    "            num_workers=4,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.configs['BATCH_SIZE'],\n",
    "            num_workers=4,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1880c",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef46134",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(pl.LightningModule):\n",
    "    def __init__(self, configs, model):\n",
    "        super().__init__()\n",
    "        self.configs=configs\n",
    "        self.model=model\n",
    "        \n",
    "        self.loss_fn1 = torch.nn.CrossEntropyLoss()\n",
    "        self.loss_fn2 = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.train_accuracy1 = MultilabelAccuracy(12)\n",
    "        self.train_accuracy2 = MultilabelAccuracy(60)\n",
    "        \n",
    "        self.val_accuracy1 = MultilabelAccuracy(12*60)\n",
    "        self.val_accuracy2 = MultilabelAccuracy(12*60)\n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        # optimizer = torch.optim.AdamW(\n",
    "        #     self.model.parameters(), lr=self.hparams.lr, weight_decay=0.01\n",
    "        # )\n",
    "        optimizer = create_optimizer_v2(\n",
    "            self.model, \"madgradw\", lr=self.configs['LEARNING_RATE'], weight_decay=configs['WEIGHT_DECAY']\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.configs['LEARNING_RATE'],\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "        )\n",
    "\n",
    "        scheduler_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "\n",
    "        return [optimizer], [scheduler_config]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y1, y2 = batch\n",
    "        y1 = y1.squeeze()\n",
    "        y2 = y2.squeeze()\n",
    "        hour, mins = self(x)\n",
    "        loss1 = self.loss_fn1(hour, y1)\n",
    "        loss2 = self.loss_fn2(mins, y2)\n",
    "        loss = loss1+loss2\n",
    "        \n",
    "        self.train_accuracy1(hour, y1)\n",
    "        self.train_accuracy2(mins, y2)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"train_acc_hour\", self.train_accuracy1, on_epoch=True)\n",
    "        self.log(\"train_acc_mins\", self.train_accuracy2, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y1, y2 = batch\n",
    "        y1 = y1.squeeze()\n",
    "        y2 = y2.squeeze()\n",
    "        hour, mins = self(x)\n",
    "        loss1 = self.loss_fn1(hour, y1)\n",
    "        loss2 = self.loss_fn2(mins, y2)\n",
    "        loss = loss1+loss2\n",
    "        \n",
    "        self.val_accuracy1(hour, y1)\n",
    "        self.val_accuracy2(mins, y2)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, on_epoch=True)\n",
    "        self.log(\"val_acc_hour\", self.val_accuracy1, on_epoch=True)\n",
    "        self.log(\"val_acc_mins\", self.val_accuracy2, on_epoch=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        logits = self(x)\n",
    "        pred = torch.sigmoid(logits)\n",
    "        return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClockClassifier(torch.nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.name = 'ClockClassifier'\n",
    "        \n",
    "        self.backbone1 = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans = 1,\n",
    "            pretrained=True,\n",
    "            num_classes=0, drop_rate=0.2\n",
    "        )\n",
    "        self.hour_classifier = torch.nn.Linear(\n",
    "            1408, 12\n",
    "        )\n",
    "        self.backbone2 = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans = 1,\n",
    "            pretrained=True,\n",
    "            num_classes=0, drop_rate=0.2\n",
    "        )\n",
    "        self.mins_classifier = torch.nn.Linear(\n",
    "            1408, 60\n",
    "        )\n",
    "        self.minute_classifier = torch.nn.Linear\n",
    "    def forward(self, x):\n",
    "        hour = self.backbone1(x)\n",
    "        hour = self.hour_classifier(hour)\n",
    "        \n",
    "        mins = self.backbone2(x)\n",
    "        mins = self.mins_classifier(mins)\n",
    "        return hour, mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98359f37",
   "metadata": {},
   "source": [
    "## run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"training start\")\n",
    "logger.info(f\"pytorch version: {torch.__version__}\")\n",
    "logger.info(\"load model\")\n",
    "\n",
    "model = ClockClassifier(model_name)\n",
    "datamodule = DataModule(\n",
    "    configs,\n",
    "    X=train['path'].values, \n",
    "    Y1=train['hour'].values, \n",
    "    Y2=train['min'].values\n",
    ")\n",
    "module = MyModule(configs=configs, model=model,)\n",
    "checkpoints = ModelCheckpoint(dirpath=folder_name, monitor=\"val_acc\", mode=\"max\")\n",
    "callbacks = [checkpoints, RichProgressBar(), LearningRateMonitor()]\n",
    "# callbacks = []\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus=configs['NUM_GPUS'],\n",
    "    accelerator=\"gpu\", strategy=\"ddp\",\n",
    "    logger=WandbLogger(name=f\"{model_name}_{now}\", project=project_name),\n",
    "    callbacks=callbacks,\n",
    "    max_epochs=configs['EPOCHS'],\n",
    "    precision=16,\n",
    "    # fast_dev_run=True,\n",
    ")\n",
    "\n",
    "logger.info(\"start training\")\n",
    "trainer.fit(module, datamodule=datamodule)\n",
    "logger.info(\"training end\")\n",
    "\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tch",
   "language": "python",
   "name": "tch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
